{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all methods not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tools.csp import generate_projection, generate_eye, extract_feature\n",
    "from tools.filters import load_filterbank\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tools.data import DreemDatasets\n",
    "from preprocessing import Compose, ExtractBands, ExtractSpectrum\n",
    "from models.riemannian_multiscale import riemannian_multiscale\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParamÃ¨tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50.  # sampling frequency\n",
    "NO_channels = 7  # number of EEG channels\n",
    "NO_riem = int(NO_channels * NO_channels + 1) / 2  # Total number of CSP feature per band and timewindow\n",
    "bw = np.array([2, 4, 8, 13, 22])\n",
    "ftype = 'butter'  # 'fir', 'butter'\n",
    "forder = 2  # 4\n",
    "filter_bank = load_filterbank(bw, fs, order=forder, max_freq=23, ftype=ftype)  # get filterbank coeffs\n",
    "time_windows_flt = np.array([[0, 30],\n",
    "                             [15, 30],\n",
    "                             [10, 25],\n",
    "                             [5, 20],\n",
    "                             [0, 15],\n",
    "                             [15, 25],\n",
    "                             [10, 20],\n",
    "                             [5, 15],\n",
    "                             [0, 10]\n",
    "]) * fs\n",
    "\n",
    "#time_windows = time_windows[0:1]  # use only largest timewindow\n",
    "\n",
    "\n",
    "riem_opt = \"No_Adaptation\"  # {\"Riemann\",\"Riemann_Euclid\",\"Whitened_Euclid\",\"No_Adaptation\"}\n",
    "rho = 0.1\n",
    "\n",
    "time_windows = time_windows_flt.astype(int)\n",
    "NO_bands = filter_bank.shape[0]\n",
    "NO_csp = 24  # Total number of CSP feature per band and timewindow\n",
    "useCSP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, train=True):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "    \n",
    "def get_data_extra_data_eeg(path, train=True):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/train_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/train_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/test/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/test/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "\n",
    "def get_extra_data(path, train=True):\n",
    "    if train:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "    \n",
    "def get_data_val(path):\n",
    "    for i in range(7):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "            X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "            X[0] = feature_0\n",
    "            del feature_0\n",
    "        else:\n",
    "            X[i] = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "def get_extrat_data_val_eeg(path):\n",
    "    for i in range(7):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "            X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "        else:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "    Y = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "def get_extra_data_val(path):\n",
    "    use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            print(feature_0.shape)\n",
    "            X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "        else:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "path = \"all\"\n",
    "train_data, train_label = get_data(path, train = True)\n",
    "test_data, test_label = get_data_val(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min - max - freq - energy on pulse et accelerometre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4, 4)\n",
      "(7658, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "path = \"all\"\n",
    "train_extra_data, train_extra_label = get_extra_data(path, train = True)\n",
    "path = \"all\"\n",
    "test_extra_data,_ = get_extra_data_val(path)\n",
    "train_extra_data = train_extra_data.reshape(-1, 4*16)\n",
    "test_extra_data = test_extra_data.reshape(-1,  4*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 381    2  250    4   98]\n",
      " [  77    1  154    1   27]\n",
      " [ 103    1 3050   66  217]\n",
      " [  26    0  432  679   49]\n",
      " [  98    2  871   14 1055]] 0.6745886654478976 0.518054836809841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(train_extra_data, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(test_extra_data)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idem sur les eegs + mm et XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7658, 7, 24)\n"
     ]
    }
   ],
   "source": [
    "path = \"all\"\n",
    "train_extra_data_eeg, train_extra_label = get_data_extra_data_eeg(path, train = True)\n",
    "path = \"all\"\n",
    "test_extra_data_eeg,_ = get_extrat_data_val_eeg(path)\n",
    "print(test_extra_data_eeg.shape)\n",
    "train_extra_data_eeg = train_extra_data_eeg.reshape(-1, 7*24)\n",
    "test_extra_data_eeg = test_extra_data_eeg.reshape(-1,  7*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 453    0  202   10   70]\n",
      " [  59    1  146    0   54]\n",
      " [  96    0 2924  104  313]\n",
      " [  21    0  388  764   13]\n",
      " [  80    0  645    8 1307]] 0.7115434839383651 0.5632674016257432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(train_extra_data_eeg, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(test_extra_data_eeg)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 232)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((train_extra_data_eeg, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((test_extra_data_eeg, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 495    0  163    5   72]\n",
      " [  72    1  142    0   45]\n",
      " [  99    0 2992   79  267]\n",
      " [  25    0  339  810   12]\n",
      " [  83    3  564    8 1382]] 0.741708017759206 0.5893988863012602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec CSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juste CSP puis concatener avec les autres (csp-acc / csp-eeg / csp acc eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, label, time_windows, useCSP = True):\n",
    "    if useCSP:\n",
    "        w = generate_projection(data, label, NO_csp, filter_bank, time_windows, NO_classes=5)\n",
    "    else:\n",
    "        w = generate_eye(data, label, filter_bank, time_windows)\n",
    "    feature_mat = extract_feature(data, w, filter_bank, time_windows)\n",
    "    return(w, feature_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, train_feat_CSP = get_features(train_data, train_label, time_windows, useCSP)\n",
    "test_feature_CSP = extract_feature(test_data, w, filter_bank, time_windows)\n",
    "#val_feature_CSP = extract_feature(val_data, w, filter_bank, time_windows)\n",
    "del w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_CSP_train = train_feat_CSP\n",
    "features_CSP_test = test_feature_CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 495    0  163    5   72]\n",
      " [  72    1  142    0   45]\n",
      " [  99    0 2992   79  267]\n",
      " [  25    0  339  810   12]\n",
      " [  83    3  564    8 1382]] 0.741708017759206 0.5893988863012602\n",
      "time :  385.4253854751587\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1198)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 491   12  155    2   75]\n",
      " [  48   23  129    0   60]\n",
      " [  65   10 2930  108  324]\n",
      " [  19    0  457  696   14]\n",
      " [  51   11  596   14 1368]] 0.7192478453904414 0.6004105644463827\n",
      "time :  950.5046248435974\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1302)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 473   10  172    4   76]\n",
      " [  40   21  135    0   64]\n",
      " [  73    7 2926  100  331]\n",
      " [  15    0  419  741   11]\n",
      " [  47    8  614   10 1361]] 0.7210759989553408 0.6016196373934014\n",
      "time :  1003.8177390098572\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1198)\n",
      "(30631, 1366)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 502    9  154    2   68]\n",
      " [  48   24  129    0   59]\n",
      " [  66   12 2952   86  321]\n",
      " [  19    0  384  773   10]\n",
      " [  56   11  590   10 1373]] 0.7343954034996083 0.6178183804270211\n",
      "time :  1015.5206558704376\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rieman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idem avec Rieman au lieu de csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f837a2ead43f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mriemann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mriemannian_multiscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_bank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_windows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mriem_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mriem_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_CSP_train_R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mriemann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeatures_CSP_test_R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mriemann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_data' is not defined"
     ]
    }
   ],
   "source": [
    "riemann = riemannian_multiscale(filter_bank, time_windows, riem_opt=riem_opt, rho=rho, vectorized=True)\n",
    "features_CSP_train_R = riemann.fit(train_data)\n",
    "features_CSP_test_R = riemann.features(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 502    9  154    2   68]\n",
      " [  48   24  129    0   59]\n",
      " [  66   12 2952   86  321]\n",
      " [  19    0  384  773   10]\n",
      " [  56   11  590   10 1373]] 0.7343954034996083 0.6178183804270211\n",
      "time :  1057.6682789325714\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(features_CSP_train_R, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(features_CSP_test_R)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4600)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, features_CSP_train), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, features_CSP_test), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
