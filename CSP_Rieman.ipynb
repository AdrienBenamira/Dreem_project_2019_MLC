{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for common spatial pattern (CSP) and Riemannian method feature calculation and classification for EEG data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tools.csp import generate_projection, generate_eye, extract_feature\n",
    "from tools.filters import load_filterbank\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tools.data import DreemDatasets\n",
    "from preprocessing import Compose, ExtractBands, ExtractSpectrum\n",
    "from models.riemannian_multiscale import riemannian_multiscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50.  # sampling frequency\n",
    "NO_channels = 7  # number of EEG channels\n",
    "NO_riem = int(NO_channels * NO_channels + 1) / 2  # Total number of CSP feature per band and timewindow\n",
    "bw = np.array([2, 4, 8, 13, 22])\n",
    "ftype = 'butter'  # 'fir', 'butter'\n",
    "forder = 2  # 4\n",
    "filter_bank = load_filterbank(bw, fs, order=forder, max_freq=23, ftype=ftype)  # get filterbank coeffs\n",
    "time_windows_flt = np.array([[0, 30],\n",
    "                            [5, 25],\n",
    "                             [15, 30],\n",
    "                             [10, 25],\n",
    "                             [5, 20],\n",
    "                             [5, 15],\n",
    "                             [0, 10],\n",
    "                             [5, 15],\n",
    "                             [15, 25],\n",
    "                             [10, 20],\n",
    "                             [5, 15],\n",
    "                             [5, 10]]) * fs\n",
    "time_windows = time_windows_flt.astype(int)\n",
    "# restrict time windows and frequency bands\n",
    "#time_windows = time_windows[0:1]  # use only largest timewindow\n",
    "\n",
    "NO_bands = filter_bank.shape[0]\n",
    "riem_opt = \"No_Adaptation\"  # {\"Riemann\",\"Riemann_Euclid\",\"Whitened_Euclid\",\"No_Adaptation\"}\n",
    "rho = 0.1\n",
    "NO_csp = 20  # Total number of CSP feature per band and timewindow\n",
    "useCSP = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset qui vont biens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut : \n",
    "    \n",
    "    1- Tout le train sans split\n",
    "    2- Tout le train avec split\n",
    "    3- Tout le train équilibré sans split\n",
    "    4- Tout le train équilibré avec split\n",
    "    5- Tout le test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_set, val_set = DreemDatasets(\\'dataset/train.h5\\', \\'dataset/train_y.csv\\', \\n                                   split_train_val=1, seed=seed, balance_data=False,keep_datasets=use_datasets).get()\\ntrain_set.save_data(\"dataset/all/train\")\\ntrain_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\\nval_set.close()\\ntrain_set, val_set = DreemDatasets(\\'dataset/train.h5\\', \\'dataset/train_y.csv\\', \\n                                   split_train_val=0.8, seed=seed, balance_data=False,keep_datasets=use_datasets).get()\\ntrain_set.save_data(\"dataset/all/train_split\")\\nval_set.save_data(\"dataset/all/val_split\")\\ntrain_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\\nval_set.close()\\ntrain_set, val_set = DreemDatasets(\\'dataset/train.h5\\', \\'dataset/train_y.csv\\', \\n                                   split_train_val=1, seed=seed, balance_data=True,keep_datasets=use_datasets).get()\\ntrain_set.save_data(\"dataset/balanced/train\")\\ntrain_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\\nval_set.close()\\ntrain_set, val_set = DreemDatasets(\\'dataset/train.h5\\', \\'dataset/train_y.csv\\', \\n                                   split_train_val=0.8, seed=seed, balance_data=True,keep_datasets=use_datasets).get()\\ntrain_set.save_data(\"dataset/balanced/train_split\")\\nval_set.save_data(\"dataset/balanced/val_split\")\\ntrain_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\\nval_set.close()\\n\\n\\nfrom tools.data import DreemDataset\\ntest_set = DreemDataset(\\'dataset/test.h5\\', keep_datasets=use_datasets).init()\\ntest_set.save_data(\"dataset/all/test\")\\ntest_set.close()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_datasets = ['accelerometer_x','accelerometer_y','accelerometer_z','eeg_1', 'eeg_2', 'eeg_3', 'eeg_4', 'eeg_5', 'eeg_6', 'eeg_7', 'pulse_oximeter_infrared']\n",
    "seed = 1\n",
    "\"\"\"train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=1, seed=seed, balance_data=False,keep_datasets=use_datasets).get()\n",
    "train_set.save_data(\"dataset/all/train\")\n",
    "train_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\n",
    "val_set.close()\n",
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=seed, balance_data=False,keep_datasets=use_datasets).get()\n",
    "train_set.save_data(\"dataset/all/train_split\")\n",
    "val_set.save_data(\"dataset/all/val_split\")\n",
    "train_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\n",
    "val_set.close()\n",
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=1, seed=seed, balance_data=True,keep_datasets=use_datasets).get()\n",
    "train_set.save_data(\"dataset/balanced/train\")\n",
    "train_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\n",
    "val_set.close()\n",
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=seed, balance_data=True,keep_datasets=use_datasets).get()\n",
    "train_set.save_data(\"dataset/balanced/train_split\")\n",
    "val_set.save_data(\"dataset/balanced/val_split\")\n",
    "train_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\n",
    "val_set.close()\"\"\"\n",
    "\n",
    "\n",
    "from tools.data import DreemDataset\n",
    "test_set = DreemDataset('dataset/test.h5', keep_datasets=use_datasets).init()\n",
    "test_set.save_data(\"dataset/all/test\")\n",
    "test_set.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, train= True,  one_vs_all = False, limit= None):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "        Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "    if one_vs_all:\n",
    "        Y[Y > 2] = 0\n",
    "        Y[Y < 2] = 0\n",
    "        Y[Y == 2] = 1\n",
    "    if limit is not None:\n",
    "        X = X[:limit]\n",
    "        Y = Y[:limit]\n",
    "    return(X, Y)\n",
    "\n",
    "#path = \"balanced\"\n",
    "#train_data, train_label = get_data(path, train = True, one_vs_all = False, limit= 1000)\n",
    "#eval_data, eval_label = get_data(path, train = False, one_vs_all = False, limit= 1000)\n",
    "#print(train_data.shape, train_label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des features par CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, label, useCSP = True, NO_csp = 20):\n",
    "    if useCSP:\n",
    "        w = generate_projection(data, label, NO_csp, filter_bank, time_windows, NO_classes=5)\n",
    "    else:\n",
    "        w = generate_eye(data, label, filter_bank, time_windows)\n",
    "    feature_mat = extract_feature(data, w, filter_bank, time_windows)\n",
    "    return(w, feature_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b6d455961ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_feat_CSP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museCSP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b6d455961ff7>\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(data, label, useCSP, NO_csp)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museCSP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNO_csp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0museCSP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNO_csp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_bank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_windows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNO_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_eye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_bank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/benamira/19793564030D4273/MCsBackup/3A/OMA/MLC/dreem-project/tools/csp.py\u001b[0m in \u001b[0;36mgenerate_projection\u001b[0;34m(data, class_vec, NO_csp, filter_bank, time_windows, NO_classes)\u001b[0m\n\u001b[1;32m     73\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNO_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                                 \u001b[0;31m#frequency band of every channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                                 \u001b[0mdata_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbutter_fir_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_bank\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubband\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                                 \u001b[0mcur_class_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/benamira/19793564030D4273/MCsBackup/3A/OMA/MLC/dreem-project/tools/filters.py\u001b[0m in \u001b[0;36mbutter_fir_filter\u001b[0;34m(signal_in, filter_coeff)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilter_coeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# butter worth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msosfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_coeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mfilter_coeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# fir filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36msosfilt\u001b[0;34m(sos, x, axis, zi)\u001b[0m\n\u001b[1;32m   3236\u001b[0m                                      x, axis, zi=zi[section])\n\u001b[1;32m   3237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_zi\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mlfilter\u001b[0;34m(b, a, x, axis, zi)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mzi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NO_time_windows = int(time_windows.size / 2)\n",
    "NO_features = NO_csp * NO_bands * NO_time_windows\n",
    "\n",
    "\n",
    "\n",
    "w, train_feat_CSP = get_features(train_data, train_label, useCSP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction des features par Riemann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_time_windows = time_windows.shape[0]\n",
    "NO_features = NO_riem * NO_bands * NO_time_windows\n",
    "riemann = riemannian_multiscale(filter_bank, time_windows, riem_opt=riem_opt, rho=rho, vectorized=True)\n",
    "train_feat_R = riemann.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_CSP = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "RF_CSP.fit(train_feat_CSP, train_label)\n",
    "\n",
    "RF_R = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "RF_R.fit(train_feat_R, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151  26   4   8  12]\n",
      " [ 53  81  23  14  39]\n",
      " [ 22  17  81  43  31]\n",
      " [ 10   6  24 152   4]\n",
      " [ 30  17  25  20 107]] 0.572 0.56199956112291\n",
      "[[152  25   5   3  16]\n",
      " [ 59  79  23   7  42]\n",
      " [ 23  17  73  50  31]\n",
      " [ 14   6  26 146   4]\n",
      " [ 25  33  22  19 100]] 0.55 0.5395647989287642\n"
     ]
    }
   ],
   "source": [
    "eval_feature_CSP = extract_feature(eval_data, w, filter_bank, time_windows)\n",
    "eval_feature_R = riemann.features(eval_data)\n",
    "\n",
    "\n",
    "labels_pred = RF_CSP.predict(eval_feature_CSP)\n",
    "CM = confusion_matrix(eval_label, labels_pred)\n",
    "Acc = accuracy_score(eval_label, labels_pred)\n",
    "F1 = f1_score(eval_label, labels_pred, average='macro')\n",
    "\n",
    "print(CM, Acc, F1)\n",
    "\n",
    "labels_pred = RF_R.predict(eval_feature_R)\n",
    "CM = confusion_matrix(eval_label, labels_pred)\n",
    "Acc = accuracy_score(eval_label, labels_pred)\n",
    "F1 = f1_score(eval_label, labels_pred, average='macro')\n",
    "\n",
    "print(CM, Acc, F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faudrait : \n",
    "\n",
    "    1 - Comprendre pk N = 20 marche\n",
    "    2 - Faire des stats sur les méthodes (temps et accuracy)      ok\n",
    "    3 - Changer RF par Perceptron\n",
    "    4 - Ajouter les features des 3 autres courbes + les probas\n",
    "    5 - Kmeans préliminaire\n",
    "    6 - Images + Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 7, 1500) (30631,)\n"
     ]
    }
   ],
   "source": [
    "path = \"all\"\n",
    "train_data, train_label = get_data(path, train = True, one_vs_all = False)\n",
    "eval_data, eval_label = get_data(path, train = False, one_vs_all = False)\n",
    "print(train_data.shape, train_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6050.65074467659\n",
      "[[ 502    5  165    4   59]\n",
      " [  37   13  149    0   61]\n",
      " [  53    4 2995   79  306]\n",
      " [  15    0  425  722   24]\n",
      " [  59    6  546    9 1420]] 0.7380517106294071 0.6062919675553691\n",
      "2918.735505580902\n",
      "[[ 464    8  179    4   80]\n",
      " [  40   16  133    0   71]\n",
      " [  76    7 2902  107  345]\n",
      " [  13    0  502  659   12]\n",
      " [  53    6  622   17 1342]] 0.7029250457038391 0.5768417304725457\n"
     ]
    }
   ],
   "source": [
    "useCSP = True\n",
    "NO_time_windows = int(time_windows.size / 2)\n",
    "start = time.time()\n",
    "w, train_feat_CSP = get_features(train_data, train_label, useCSP)\n",
    "RF_CSP = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "RF_CSP.fit(train_feat_CSP, train_label)\n",
    "eval_feature_CSP = extract_feature(eval_data, w, filter_bank, time_windows)\n",
    "np.save(\"features_CSP_train_split_True.npy\", train_feat_CSP)\n",
    "np.save(\"features_CSP_val_split_True.npy\", eval_feature_CSP)\n",
    "labels_pred = RF_CSP.predict(eval_feature_CSP)\n",
    "CM = confusion_matrix(eval_label, labels_pred)\n",
    "Acc = accuracy_score(eval_label, labels_pred)\n",
    "F1 = f1_score(eval_label, labels_pred, average='macro')\n",
    "print(time.time()-start)\n",
    "print(CM, Acc, F1)\n",
    "\n",
    "useCSP = False\n",
    "NO_time_windows = int(time_windows.size / 2)\n",
    "start = time.time()\n",
    "w, train_feat_CSP = get_features(train_data, train_label, useCSP)\n",
    "RF_CSP = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "RF_CSP.fit(train_feat_CSP, train_label)\n",
    "eval_feature_CSP = extract_feature(eval_data, w, filter_bank, time_windows)\n",
    "np.save(\"features_CSP_train_split_False.npy\", train_feat_CSP)\n",
    "np.save(\"features_CSP_val_split_False.npy\", eval_feature_CSP)\n",
    "labels_pred = RF_CSP.predict(eval_feature_CSP)\n",
    "CM = confusion_matrix(eval_label, labels_pred)\n",
    "Acc = accuracy_score(eval_label, labels_pred)\n",
    "F1 = f1_score(eval_label, labels_pred, average='macro')\n",
    "print(time.time()-start)\n",
    "print(CM, Acc, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5549.880460977554\n",
      "[[ 480    5  179    0   71]\n",
      " [  44   12  140    0   64]\n",
      " [  55    6 2934  110  332]\n",
      " [  17    1  499  657   12]\n",
      " [  46    8  598   18 1370]] 0.7120658135283364 0.5808282267416092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyriemann/utils/base.py:12: RuntimeWarning: invalid value encountered in log\n",
      "  eigvals = numpy.diag(operator(eigvals))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrices must be positive definite. Add regularization to avoid this error.\n",
      "Input contains NaN, infinity or a value too large for dtype('float32').\n",
      "4730.435000419617\n",
      "[[ 480    2  196    5   52]\n",
      " [  48    6  159    3   44]\n",
      " [  52    3 3021   79  282]\n",
      " [  11    0  541  567   67]\n",
      " [  57    3  745   38 1197]] 0.6882998171846435 0.5475961588532392\n",
      "5817.639447450638\n",
      "[[ 480    5  179    0   71]\n",
      " [  44   12  140    0   64]\n",
      " [  55    6 2934  110  332]\n",
      " [  17    1  499  657   12]\n",
      " [  46    8  598   18 1370]] 0.7120658135283364 0.5808282267416092\n"
     ]
    }
   ],
   "source": [
    "methods = [\"No_Adaptation\", \"Riemann\",\"Riemann_Euclid\",\"Whitened_Euclid\",\"No_Adaptation\"]\n",
    "NO_time_windows = time_windows.shape[0]\n",
    "for riem_opt in methods:\n",
    "    try:\n",
    "        start = time.time()\n",
    "        NO_time_windows = time_windows.shape[0]\n",
    "        NO_features = NO_riem * NO_bands * NO_time_windows\n",
    "        riemann = riemannian_multiscale(filter_bank, time_windows, riem_opt=riem_opt, rho=rho, vectorized=True)\n",
    "        train_feat_R = riemann.fit(train_data)\n",
    "        RF_R = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "        RF_R.fit(train_feat_R, train_label)\n",
    "        eval_feature_R = riemann.features(eval_data)\n",
    "        np.save(\"features_R_train_split_\"+str(riem_opt), train_feat_CSP)\n",
    "        np.save(\"features_R_val_split_\"+str(riem_opt), eval_feature_CSP)\n",
    "        labels_pred = RF_R.predict(eval_feature_R)\n",
    "        CM = confusion_matrix(eval_label, labels_pred)\n",
    "        Acc = accuracy_score(eval_label, labels_pred)\n",
    "        F1 = f1_score(eval_label, labels_pred, average='macro')\n",
    "        print(time.time()-start)\n",
    "        print(CM, Acc, F1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF - Boosting - NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.features import ExtractFeatures\n",
    "extract_features = ExtractFeatures(bands='*', features=['min', 'max', 'energy', 'frequency'])\n",
    "\n",
    "transformations = {\n",
    "    \"XXX\": extract_features,\n",
    "    \"XXX\": extract_features,\n",
    "    \"XXX\": extract_features\n",
    "}\n",
    "\n",
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=seed, keep_datasets=use_datasets,\n",
    "                                   transforms=dataset_transform_spectrum).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
