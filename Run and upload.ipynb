{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all train, all test and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tools.csp import generate_projection, generate_eye, extract_feature\n",
    "from tools.filters import load_filterbank\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tools.data import DreemDatasets\n",
    "from preprocessing import Compose, ExtractBands, ExtractSpectrum\n",
    "from models.riemannian_multiscale import riemannian_multiscale\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50.  # sampling frequency\n",
    "NO_channels = 7  # number of EEG channels\n",
    "NO_riem = int(NO_channels * NO_channels + 1) / 2  # Total number of CSP feature per band and timewindow\n",
    "bw = np.array([2, 4, 8, 13, 22])\n",
    "ftype = 'butter'  # 'fir', 'butter'\n",
    "forder = 2  # 4\n",
    "filter_bank = load_filterbank(bw, fs, order=forder, max_freq=23, ftype=ftype)  # get filterbank coeffs\n",
    "time_windows_flt = np.array([[0, 30],\n",
    "                            [5, 25],\n",
    "                             [15, 30],\n",
    "                             [10, 25],\n",
    "                             [5, 20],\n",
    "                             [5, 15],\n",
    "                             [0, 10],\n",
    "                             [5, 15],\n",
    "                             [15, 25],\n",
    "                             [10, 20],\n",
    "                             [5, 15],\n",
    "                             [5, 10]]) * fs\n",
    "time_windows = time_windows_flt.astype(int)\n",
    "# restrict time windows and frequency bands\n",
    "#time_windows = time_windows[0:1]  # use only largest timewindow\n",
    "\n",
    "NO_bands = filter_bank.shape[0]\n",
    "riem_opt = \"No_Adaptation\"  # {\"Riemann\",\"Riemann_Euclid\",\"Whitened_Euclid\",\"No_Adaptation\"}\n",
    "rho = 0.1\n",
    "NO_csp = 20  # Total number of CSP feature per band and timewindow\n",
    "useCSP = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo : \n",
    "\n",
    "    1- refaire l'embedding du test avc le train split + résultats sans extra data\n",
    "    2- refaire résultats du test avc le all train sans extra data\n",
    "    3- résultats du 2 avec extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, train=True):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/train/eeg_\" + str(i + 1) + \".npy\")\n",
    "        Y = np.load(\"dataset/\"+path+\"/train/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "\n",
    "def get_extra_data(path, train=True):\n",
    "    if train:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "    \n",
    "def get_data_val(path):\n",
    "    for i in range(7):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "            X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "            X[0] = feature_0\n",
    "            del feature_0\n",
    "        else:\n",
    "            X[i] = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "def get_extra_data_val(path):\n",
    "    use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            print(feature_0.shape)\n",
    "            X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "        else:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data_train,data_test, label, useCSP = True, NO_csp = 20):\n",
    "    if useCSP:\n",
    "        w = generate_projection(data_train, label, NO_csp, filter_bank, time_windows, NO_classes=5)\n",
    "    else:\n",
    "        w = generate_eye(data_train, label, filter_bank, time_windows)\n",
    "    #feature_train = extract_feature(data_train, w, filter_bank, time_windows)\n",
    "    feature_test = extract_feature(data_test, w, filter_bank, time_windows)\n",
    "    return(w, feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3581.9479615688324\n",
      "end CSP true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nuseCSP = False\\nstart = time.time()\\nw, train_feat_CSP, test_feat_CSP = get_features(train_data, test_data, train_label, useCSP)\\nnp.save(\"features_CSP_train_False.npy\", train_feat_CSP)\\nnp.save(\"features_CSP_test_False.npy\", test_feat_CSP)\\nprint(time.time()-start)\\nprint(\"end CSP False\")\\n\\ndel w\\ndel train_feat_CSP\\ndel test_feat_CSP\\n\\nmethods = [\"No_Adaptation\",\"Whitened_Euclid\"]\\nfor riem_opt in methods:\\n    try:\\n        start = time.time()\\n        riemann = riemannian_multiscale(filter_bank, time_windows, riem_opt=riem_opt, rho=rho, vectorized=True)\\n        train_feat_R = riemann.fit(train_data)\\n        test_feature_R = riemann.features(test_data)\\n        np.save(\"features_R_train_\"+str(riem_opt), train_feat_CSP)\\n        np.save(\"features_R_test_\"+str(riem_opt), test_feature_R)\\n        print(time.time()-start)\\n        print(riem_opt)\\n        del train_feat_R\\n        del test_feature_R\\n    except Exception as e:\\n        print(e)\\n        del train_feat_R\\n        del test_feature_R\\n        pass\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"all\"\n",
    "\n",
    "train_data, train_label = get_data(path, train = True)\n",
    "test_data = get_data(path, train = False)\n",
    "\n",
    "\n",
    "useCSP = True\n",
    "start = time.time()\n",
    "w, test_feat_CSP = get_features(train_data, test_data, train_label, useCSP)\n",
    "del w\n",
    "np.save(\"features_CSP_test_with_train_split_True.npy\", test_feat_CSP)\n",
    "print(time.time()-start)\n",
    "print(\"end CSP true\")\n",
    "del test_feat_CSP\n",
    "\"\"\"\n",
    "useCSP = False\n",
    "start = time.time()\n",
    "w, train_feat_CSP, test_feat_CSP = get_features(train_data, test_data, train_label, useCSP)\n",
    "np.save(\"features_CSP_train_False.npy\", train_feat_CSP)\n",
    "np.save(\"features_CSP_test_False.npy\", test_feat_CSP)\n",
    "print(time.time()-start)\n",
    "print(\"end CSP False\")\n",
    "\n",
    "del w\n",
    "del train_feat_CSP\n",
    "del test_feat_CSP\n",
    "\n",
    "methods = [\"No_Adaptation\",\"Whitened_Euclid\"]\n",
    "for riem_opt in methods:\n",
    "    try:\n",
    "        start = time.time()\n",
    "        riemann = riemannian_multiscale(filter_bank, time_windows, riem_opt=riem_opt, rho=rho, vectorized=True)\n",
    "        train_feat_R = riemann.fit(train_data)\n",
    "        test_feature_R = riemann.features(test_data)\n",
    "        np.save(\"features_R_train_\"+str(riem_opt), train_feat_CSP)\n",
    "        np.save(\"features_R_test_\"+str(riem_opt), test_feature_R)\n",
    "        print(time.time()-start)\n",
    "        print(riem_opt)\n",
    "        del train_feat_R\n",
    "        del test_feature_R\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        del train_feat_R\n",
    "        del test_feature_R\n",
    "        pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4, 4)\n",
      "(7658, 4, 4)\n",
      "(37439, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "path = \"all\"\n",
    "#_, train_label = get_data(path, train = True)\n",
    "train_extra_data, train_extra_label = get_extra_data(path, train = True)\n",
    "val_extra_data, val_extra_label = get_extra_data_val(path)\n",
    "test_extra_data = get_extra_data(path, train = False)\n",
    "train_extra_data = train_extra_data.reshape(-1, 4*16)\n",
    "val_extra_data = val_extra_data.reshape(-1, 4*16)\n",
    "test_extra_data = test_extra_data.reshape(-1,  4*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4320)\n",
      "(37439, 4320)\n"
     ]
    }
   ],
   "source": [
    "#_, train_label = get_data(path, train = True)\n",
    "features_CSP_train = np.load(\"dataset/all/features_CSP_train_split_True.npy\")\n",
    "features_CSP_val = np.load(\"dataset/all/features_CSP_val_split_True.npy\")\n",
    "features_CSP_test = np.load(\"features_CSP_test_with_train_split_True.npy\")\n",
    "\n",
    "all_final_features = features_CSP_train\n",
    "all_final_features_test = features_CSP_test\n",
    "all_final_features_val = features_CSP_val\n",
    "\n",
    "#all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "#all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "#all_final_features_val = np.concatenate((features_CSP_val, val_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "print(all_final_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(all_final_features, train_extra_label)\n",
    "print(\"trained\")\n",
    "labels_pred = clf.predict(all_final_features_val)\n",
    "print(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 495   10  154    5   71]\n",
      " [  40   11  147    0   62]\n",
      " [  55    5 2935   94  348]\n",
      " [  15    1  437  702   31]\n",
      " [  57    7  558   14 1404]] 0.7243405588926612 0.5920934903258285\n"
     ]
    }
   ],
   "source": [
    "CM = confusion_matrix(val_extra_label, labels_pred)\n",
    "Acc = accuracy_score(val_extra_label, labels_pred)\n",
    "F1 = f1_score(val_extra_label, labels_pred, average='macro')\n",
    "\n",
    "print(CM, Acc, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "df = pd.DataFrame(labels_pred)\n",
    "df.to_csv('label_pred2.csv', header=[\"sleep_stage\"])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4384)\n",
      "(37439, 4384)\n",
      "trained\n",
      "predicted\n",
      "[[ 525    9  145    1   55]\n",
      " [  54   20  124    1   61]\n",
      " [  65    4 2969   89  310]\n",
      " [  18    1  419  732   16]\n",
      " [  54   11  555   12 1408]] 0.7383128754243928 0.6158796718010775\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "all_final_features_val = np.concatenate((features_CSP_val, val_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "print(all_final_features_test.shape)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(all_final_features, train_extra_label)\n",
    "print(\"trained\")\n",
    "labels_pred = clf.predict(all_final_features_val)\n",
    "print(\"predicted\")\n",
    "\n",
    "CM = confusion_matrix(val_extra_label, labels_pred)\n",
    "Acc = accuracy_score(val_extra_label, labels_pred)\n",
    "F1 = f1_score(val_extra_label, labels_pred, average='macro')\n",
    "\n",
    "print(CM, Acc, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\n"
     ]
    }
   ],
   "source": [
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(labels_pred)\n",
    "df.to_csv('label_pred.csv', header=[\"sleep_stage\"])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}