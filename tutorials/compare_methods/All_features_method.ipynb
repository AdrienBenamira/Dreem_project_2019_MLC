{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all methods not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tools.csp import generate_projection, generate_eye, extract_feature\n",
    "from tools.filters import load_filterbank\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tools.data import DreemDatasets\n",
    "from preprocessing import Compose, ExtractBands, ExtractSpectrum\n",
    "from models.riemannian_multiscale import riemannian_multiscale\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParamÃ¨tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50.  # sampling frequency\n",
    "NO_channels = 7  # number of EEG channels\n",
    "NO_riem = int(NO_channels * NO_channels + 1) / 2  # Total number of CSP feature per band and timewindow\n",
    "bw = np.array([2, 4, 8, 13, 22])\n",
    "ftype = 'butter'  # 'fir', 'butter'\n",
    "forder = 2  # 4\n",
    "filter_bank = load_filterbank(bw, fs, order=forder, max_freq=23, ftype=ftype)  # get filterbank coeffs\n",
    "time_windows_flt = np.array([[0, 30],\n",
    "                             [15, 30],\n",
    "                             [10, 25],\n",
    "                             [5, 20],\n",
    "                             [0, 15],\n",
    "                             [15, 25],\n",
    "                             [10, 20],\n",
    "                             [5, 15],\n",
    "                             [0, 10]\n",
    "]) * fs\n",
    "\n",
    "#time_windows = time_windows[0:1]  # use only largest timewindow\n",
    "\n",
    "\n",
    "riem_opt = \"No_Adaptation\"  # {\"Riemann\",\"Riemann_Euclid\",\"Whitened_Euclid\",\"No_Adaptation\"}\n",
    "rho = 0.1\n",
    "\n",
    "time_windows = time_windows_flt.astype(int)\n",
    "NO_bands = filter_bank.shape[0]\n",
    "NO_csp = 24  # Total number of CSP feature per band and timewindow\n",
    "useCSP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, train=True):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "    \n",
    "def get_data_extra_data_eeg(path, train=True):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/train_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/train_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/test/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/test/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "\n",
    "def get_extra_data(path, train=True):\n",
    "    if train:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "    \n",
    "def get_data_val(path):\n",
    "    for i in range(7):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "            X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "            X[0] = feature_0\n",
    "            del feature_0\n",
    "        else:\n",
    "            X[i] = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "def get_extrat_data_val_eeg(path):\n",
    "    for i in range(7):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "            X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "        else:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "    Y = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "def get_extra_data_val(path):\n",
    "    use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            print(feature_0.shape)\n",
    "            X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "        else:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "path = \"all\"\n",
    "train_data, train_label = get_data(path, train = True)\n",
    "test_data, test_label = get_data_val(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min - max - freq - energy on pulse et accelerometre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4, 4)\n",
      "(7658, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "path = \"all\"\n",
    "train_extra_data, train_extra_label = get_extra_data(path, train = True)\n",
    "path = \"all\"\n",
    "test_extra_data,_ = get_extra_data_val(path)\n",
    "train_extra_data = train_extra_data.reshape(-1, 4*16)\n",
    "test_extra_data = test_extra_data.reshape(-1,  4*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 381    2  250    4   98]\n",
      " [  77    1  154    1   27]\n",
      " [ 103    1 3050   66  217]\n",
      " [  26    0  432  679   49]\n",
      " [  98    2  871   14 1055]] 0.6745886654478976 0.518054836809841\n",
      "time :  193.4650731086731\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(train_extra_data, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(test_extra_data)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idem sur les eegs + mm et XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7658, 7, 24)\n"
     ]
    }
   ],
   "source": [
    "path = \"all\"\n",
    "train_extra_data_eeg, train_extra_label = get_data_extra_data_eeg(path, train = True)\n",
    "path = \"all\"\n",
    "test_extra_data_eeg,_ = get_extrat_data_val_eeg(path)\n",
    "print(test_extra_data_eeg.shape)\n",
    "train_extra_data_eeg = train_extra_data_eeg.reshape(-1, 7*24)\n",
    "test_extra_data_eeg = test_extra_data_eeg.reshape(-1,  7*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 453    0  202   10   70]\n",
      " [  59    1  146    0   54]\n",
      " [  96    0 2924  104  313]\n",
      " [  21    0  388  764   13]\n",
      " [  80    0  645    8 1307]] 0.7115434839383651 0.5632674016257432\n",
      "time :  308.0689322948456\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(train_extra_data_eeg, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(test_extra_data_eeg)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 232)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((train_extra_data_eeg, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((test_extra_data_eeg, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 495    0  163    5   72]\n",
      " [  72    1  142    0   45]\n",
      " [  99    0 2992   79  267]\n",
      " [  25    0  339  810   12]\n",
      " [  83    3  564    8 1382]] 0.741708017759206 0.5893988863012602\n",
      "time :  403.27120065689087\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec CSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juste CSP puis concatener avec les autres (csp-acc / csp-eeg / csp acc eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data, label, time_windows, useCSP = True):\n",
    "    if useCSP:\n",
    "        w = generate_projection(data, label, NO_csp, filter_bank, time_windows, NO_classes=5)\n",
    "    else:\n",
    "        w = generate_eye(data, label, filter_bank, time_windows)\n",
    "    feature_mat = extract_feature(data, w, filter_bank, time_windows)\n",
    "    return(w, feature_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, train_feat_CSP = get_features(train_data, train_label, time_windows, useCSP)\n",
    "test_feature_CSP = extract_feature(test_data, w, filter_bank, time_windows)\n",
    "#val_feature_CSP = extract_feature(val_data, w, filter_bank, time_windows)\n",
    "del w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_CSP_train = train_feat_CSP\n",
    "features_CSP_test = test_feature_CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 470    9  179    3   74]\n",
      " [  43   19  130    0   68]\n",
      " [  71   10 2904  104  348]\n",
      " [  16    0  486  672   12]\n",
      " [  54    4  625   14 1343]] 0.7061896056411596 0.5842877621848805\n",
      "time :  919.6256680488586\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(features_CSP_train, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(features_CSP_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1198)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 491   12  155    2   75]\n",
      " [  48   23  129    0   60]\n",
      " [  65   10 2930  108  324]\n",
      " [  19    0  457  696   14]\n",
      " [  51   11  596   14 1368]] 0.7192478453904414 0.6004105644463827\n",
      "time :  1096.9947135448456\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1302)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 473   10  172    4   76]\n",
      " [  40   21  135    0   64]\n",
      " [  73    7 2926  100  331]\n",
      " [  15    0  419  741   11]\n",
      " [  47    8  614   10 1361]] 0.7210759989553408 0.6016196373934014\n",
      "time :  1151.7565553188324\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1198)\n",
      "(30631, 1366)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 502    9  154    2   68]\n",
      " [  48   24  129    0   59]\n",
      " [  66   12 2952   86  321]\n",
      " [  19    0  384  773   10]\n",
      " [  56   11  590   10 1373]] 0.7343954034996083 0.6178183804270211\n",
      "time :  1332.3991961479187\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rieman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idem avec Rieman au lieu de csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "riemann = riemannian_multiscale(filter_bank, time_windows, riem_opt=riem_opt, rho=rho, vectorized=True)\n",
    "features_CSP_train_R = riemann.fit(train_data)\n",
    "features_CSP_test_R = riemann.features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 484    7  174    0   70]\n",
      " [  44   15  133    0   68]\n",
      " [  57    8 2949  107  316]\n",
      " [  21    0  490  665   10]\n",
      " [  50   10  596   15 1369]] 0.7158527030556281 0.5870286488868578\n",
      "time :  2091.5074892044067\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(features_CSP_train_R, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(features_CSP_test_R)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4600)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 495    6  165    0   69]\n",
      " [  52   19  129    0   60]\n",
      " [  66   13 2938  104  316]\n",
      " [  18    1  491  667    9]\n",
      " [  47   13  587   16 1377]] 0.7176808566205276 0.5936981532731522\n",
      "time :  2749.4361786842346\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4704)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 484    6  174    0   71]\n",
      " [  41   18  129    0   72]\n",
      " [  53   10 2970   87  317]\n",
      " [  18    0  452  705   11]\n",
      " [  52   10  602   11 1365]] 0.7236876469051972 0.5993303214694508\n",
      "time :  2546.7298605442047\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4600)\n",
      "(30631, 4768)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 498    8  162    0   67]\n",
      " [  50   19  130    0   61]\n",
      " [  65   10 2961   87  314]\n",
      " [  16    1  441  718   10]\n",
      " [  43   14  605    8 1370]] 0.7268216244450248 0.6046064049161487\n",
      "time :  2495.229054927826\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4600)\n",
      "(30631, 4768)\n",
      "(30631, 5902)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, features_CSP_train), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, features_CSP_test), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[ 500    7  165    0   63]\n",
      " [  50   20  129    0   61]\n",
      " [  67   11 2960   84  315]\n",
      " [  18    0  437  722    9]\n",
      " [  42   11  599   12 1376]] 0.7283886132149386 0.6073168052488374\n",
      "time :  2750.351104259491\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=700,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"features_CSP_false_allfenetres_sans0_train.npy\", features_CSP_train)\n",
    "np.save(\"features_CSP_false_allfenetres_sans0_test.npy\", features_CSP_test)\n",
    "np.save(\"features_R_allfenetres_sans0_train.npy\", features_CSP_train_R)\n",
    "np.save(\"features_R_allfenetres_sans0_test.npy\", features_CSP_test_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : \n",
    "\n",
    "Deal with unbalanced data et UP le label 1\n",
    "\n",
    "Normaliser les donnÃ©es (avant et aprÃ¨s le prÃ©proscess ?)\n",
    "\n",
    "Cross val et hyper parametres RF, SVM gradient boosting\n",
    "\n",
    "https://stats.stackexchange.com/questions/260736/multiclass-classification-having-class-imbalance-with-gradient-boosting-classifi\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "ya github \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
