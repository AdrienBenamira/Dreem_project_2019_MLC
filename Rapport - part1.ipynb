{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning and Classification \n",
    "## Rapport du projet\n",
    "\n",
    "*Par BENAMIRA Adrien, CARRIE Hanaé et DEVILLERS Benjamin*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blabla à propos de l'obj..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des données et pré-traitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Chargement des données\n",
    "\n",
    "Les données sont sauvegardée au format HDF5. Ce format est particulièrement intéressant car il permet de stocker des lourdes données compréssées en un dataset. La bibliothèque Python `h5py` permet de pouvoir les lire ces données facilement de la même manière que nous utiliserions un tableau `Numpy`.\n",
    "\n",
    "La class python `DreemDataset` dans le package `tools.data` permet de récupérer et manipuler les datasets.\n",
    "Comme nous voulons effectuer des prétraitements sur nos données et les stocker pour pouvoir rapidement appliquer les algorithmes d'apprentissage sur nos données traitées, nous avons conçu cette classe de sorte que nous puissions appliquer puis sauvegarder.\n",
    "\n",
    "Nous avons choisis de les sauvegarder ensuite dans des tableaux `npy` pour des questions de performances d'execution.\n",
    "\n",
    "La classe python `DreemDatasets` permet quant à elle de générer un \"dev set\" et \"train set\" à partir des données. Celle-ci retourne un couple d'instance de `DreemDataset`. Puis que les différentes classes ne sont pas équilibrées, nous pouvons également ne récupérer qu'un sous-ensemble du dataset équilibré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.data import DreemDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres sont :\n",
    "\n",
    "- chemin vers les données\n",
    "- chemin vers les cibles\n",
    "- `keep_datasets` Liste des datasets à garder, parmi les suivants :\n",
    "    * `eeg_1` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_2` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_3` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_4` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_5` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_6` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_7` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `accelerometer_x` - Accelerometer along x axis sampled at 10 Hz -> 300 values\n",
    "    * `accelerometer_y` - Accelerometer along y axis sampled at 10 Hz -> 300 values\n",
    "    * `accelerometer_z` - Accelerometer along z axis sampled at 10 Hz -> 300 values\n",
    "    * `pulse_oximeter_infrared` - Pulse oximeter infrared channel sampled at 10 Hz -> 300 values\n",
    "- `split_train_val` Pourcentage pour partager le train set et validation set\n",
    "- `seed` Une seed pour la reproductibilité\n",
    "- `balance_data` si vrai, équilibre le dataset pour avoir le nombre de donnée par classe\n",
    "- `size` Une taille maximale pour le dataset (si non renseignée, tout le dataset)\n",
    "- `transforms` des transformations à appliquer aux données (voir la partie transformation)\n",
    "- `transforms_val` si renseignée, `transforms` sera pour le train et `transforms_val` pour la validation. Sinon, même transformation que `transforms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "5412 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n",
      "Loading data in memory...\n",
      "1353 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', \n",
    "                                   'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, \n",
    "                                   seed=0, \n",
    "                                   keep_datasets=['eeg_1']).get()\n",
    "\n",
    "train_set.load_data()  # Load les données en mémoire\n",
    "\n",
    "val_set.load_data()\n",
    "\n",
    "# Ne pas oublier de fermer les datasets\n",
    "# Ne ferme que les fichiers h5. Si .load_data() a été appelé, on a toujours accès aux données !\n",
    "train_set.close()\n",
    "val_set.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Récupération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1500)\n",
      "(1, 10, 1500)\n"
     ]
    }
   ],
   "source": [
    "data_50hz, data_10hz, target = train_set[0]  # Une valeur\n",
    "\n",
    "# Dimension nb_datasets x tailles_features\n",
    "print(data_50hz.shape)\n",
    "\n",
    "data_50hz, data_10hz, targets = train_set[:10]  # 10 valeurs\n",
    "# Dimension nb_datasets x nb_elements (=10) x tailles_features\n",
    "\n",
    "print(data_50hz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Enregistrer un dataset\n",
    "\n",
    "On peut utiliser la méthode `save_data` pour enregistrer dans un `.npy`. Pour des questions de mémoire, il y aura un fichier par dataset (ex, si on choisit d'ouvrir `[\"eeg_1\", \"eeg_2\"]` alors il y aura deux fichiers).\n",
    "\n",
    "Attention, le nom des fichiers ne peut pas être précisé, seulement un dossier parent.\n",
    "\n",
    "Par exemple, avec le `save_data(\"dataset/test\")`, on aura les fichiers :\n",
    "- `dataset/test/eeg_1.npy`\n",
    "- `dataset/test/eeg_2.npy`\n",
    "\n",
    "On peut préciser le chemin vers un nouveau dossier, celui-ci sera créé.\n",
    "\n",
    "La sauvegarde enregistre les données **transformée**. Les données brutes ne sont pas enregistrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving into dataset/sauvegarde/train ...\n",
      "Loading dataset eeg_1 ...\n",
      "Saved.\n",
      "Saving into dataset/sauvegarde/val ...\n",
      "Loading dataset eeg_1 ...\n",
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=0, keep_datasets=['eeg_1']).get()\n",
    "\n",
    "train_set.save_data(\"dataset/sauvegarde/train\")  # Attention, pas de / à la fin !\n",
    "val_set.save_data(\"dataset/sauvegarde/val\")\n",
    "\n",
    "train_set.close()\n",
    "val_set.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on a déjà enregistré le dataset, on peut utiliser `load_data` en précisant le dossier dans lequel sont tous les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "5412 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n",
      "Loading data in memory...\n",
      "1353 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n",
      "(1, 1500)\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=0, keep_datasets=['eeg_1']).get()\n",
    "\n",
    "# Cela remplace les données données des fichiers h5.\n",
    "train_set.load_data(\"dataset/sauvegarde/train\")  # Attention, pas de / à la fin !\n",
    "val_set.load_data(\"dataset/sauvegarde/val\")\n",
    "\n",
    "train_set.close()\n",
    "val_set.close()\n",
    "\n",
    "data_50hz, data_10hz, target = train_set[0]\n",
    "\n",
    "print(data_50hz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. Test set\n",
    "\n",
    "On peut faire la même chose avec le test set qu'avec les autres données.\n",
    "\n",
    "Attention à bien appeler `init()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "37439 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from tools.data import DreemDataset\n",
    "\n",
    "test_set = DreemDataset('dataset/test.h5', keep_datasets=['eeg_1']).init()\n",
    "\n",
    "# Rappel : charge en mémoire. On peut également charget un fichier en précisant un chemin\n",
    "test_set.load_data()  \n",
    "\n",
    "test_set.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Pré-traitements\n",
    "\n",
    "#### 2.2.1. Introduction : Transformations\n",
    "\n",
    "Une transformation est ce qui nous permet de faire nos pré-traitements sur nos données.\n",
    "Pour effectuer des transformations sur nos données, nous devons definir un dictionnaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_eeg_1(batch_signals, batch_targets):\n",
    "    return batch_signals[:, 0]\n",
    "\n",
    "transformations = {\n",
    "    \"eeg_1\": transformation_eeg_1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prenant en clé le nom du dataset sur lequel effectuer la transformation et en valeur une fonction prenant 2 paramètres :\n",
    "\n",
    "* un batch du signal de taille (batch, taille_signal)\n",
    "* les \"targets\" qui correspondent aux classes de sommeils que nous devons prédire pour le batch en question.\n",
    "\n",
    "Ces deux paramètres peuvent être utiles pour nos différentes fonctions de pré-processing.\n",
    "\n",
    "La transformation doit retourner le batch modifié.\n",
    "\n",
    "Dans l'exemple ci-dessus, nous appliquerons une transformation au dataset `eeg_1` qui tranformera les signaux en seulement la première valeur du signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Extraction en bandes\n",
    "\n",
    "D'après [[1: Malhotra, R. K., & Avidan, A. Y. (2014). Sleep stages and scoring technique. Atlas of Sleep Medicine, 77-99.](http://www.fmed.edu.uy/sites/www.labsueno.fmed.edu.uy/files/9.Diagnostico-polisomnogr%C3%A1fico.pdf)] et [[2: Aboalayon, K., Faezipour, M., Almuhammadi, W., & Moslehpour, S. (2016). Sleep stage classification using EEG signal analysis: a comprehensive survey and new investigation. Entropy, 18(9), 272.](https://www.mdpi.com/1099-4300/18/9/272)], les électroencéphalogrames (eegs) peuvent être séparés en bande de fréquences contenant différentes informations :\n",
    "\n",
    "* Bande $\\delta$ : de 0 à 4 Hz,\n",
    "* bande $\\theta$ : de 4 à 8 Hz,\n",
    "* bande $\\alpha$ : de 8 à 13 Hz,\n",
    "* bande $\\beta$ : de 13 à 38 Hz,\n",
    "* bande $\\gamma$ : de 38 à 42 Hz.\n",
    "\n",
    "Cependant nos eegs sont échantillonés à 50 Hz. Le thèorème de Shannon (Sampling theorem) indique que nous ne pourrons récupérer que des informations sur une bande de fréquence entre 0 et 25 Hz.\n",
    "\n",
    "Nous ne considerons donc pour cela pas la bande $\\gamma$ et gardon la bande $\\beta$ que de 13 à 22 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.signals import ExtractBands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_bands = ExtractBands(bands='*')  # toutes les bandes (de delta à beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`extract_bands` est une transformation que nous pouvons appliquer aux eegs et qui sort des signaux extraits en bande :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "5412 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Apply transformations...\n",
      "Applied.\n",
      "Done.\n",
      "Loading data in memory...\n",
      "1353 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Apply transformations...\n",
      "Applied.\n",
      "Done.\n",
      "(1, 4, 1500)\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', \n",
    "                                   'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, \n",
    "                                   seed=0, \n",
    "                                   keep_datasets=['eeg_1'],\n",
    "                                   transforms={\"eeg_1\": extract_bands}).get()\n",
    "\n",
    "train_set.load_data()  # Load les données en mémoire\n",
    "\n",
    "val_set.load_data()\n",
    "\n",
    "# Ne pas oublier de fermer les datasets\n",
    "# Ne ferme que les fichiers h5. Si .load_data() a été appelé, on a toujours accès aux données !\n",
    "train_set.close()\n",
    "val_set.close()\n",
    "\n",
    "data_50hz, data_10hz, target = train_set[0]\n",
    "\n",
    "print(data_50hz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter la dimension \"4\" ajoutée qui correspond aux 4 bandes de fréquence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3. Features plus avancées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons ensuite ajouté différents pré-traitements de base sur nos features tel que :\n",
    "\n",
    "* `min` valeur min du signal,\n",
    "* `max` valeur max du signal,\n",
    "* `frequency` fréquence du signal,\n",
    "* `energy` énergie du signal.\n",
    "\n",
    "Puis nous avons essayé les features proposés par [[2](https://www.mdpi.com/1099-4300/18/9/272)] :\n",
    "* `mmd` distance minimum-maximum\n",
    "* `esis` correspond à l'énergie et \"vitesse\" du signal\n",
    "\n",
    "De plus, comme expliqué par [[1](http://www.fmed.edu.uy/sites/www.labsueno.fmed.edu.uy/files/9.Diagnostico-polisomnogr%C3%A1fico.pdf)], section \"_Stages of Sleep_\", nous pouvons distinguer différentes étapes du sommeil par différentes prédominances \"d'utilisation\" d'une bande :\n",
    "* `band-usage` est la feature qui indique, sur une fenêtre glissante, la bande qui est a la plus grande valeur sur la fenêtre parmi toutes les bandes. Cela donne une indication de la bande prédominante sur la fenêtre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation pour ces featyres\n",
    "from preprocessing.features import ExtractFeatures\n",
    "\n",
    "# Extract features peut directement extraire les bandes\n",
    "extract_features = ExtractFeatures(bands='*', features=['mmd', 'esis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "5412 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Apply transformations...\n",
      "Applied.\n",
      "Done.\n",
      "Loading data in memory...\n",
      "1353 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Apply transformations...\n",
      "Applied.\n",
      "Done.\n",
      "(1, 4, 5412, 2)\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', \n",
    "                                   'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, \n",
    "                                   seed=0, \n",
    "                                   keep_datasets=['eeg_1'],\n",
    "                                   transforms={\"eeg_1\": extract_features}).get()\n",
    "\n",
    "train_set.load_data()  # Load les données en mémoire\n",
    "\n",
    "val_set.load_data()\n",
    "\n",
    "# Ne pas oublier de fermer les datasets\n",
    "# Ne ferme que les fichiers h5. Si .load_data() a été appelé, on a toujours accès aux données !\n",
    "train_set.close()\n",
    "val_set.close()\n",
    "\n",
    "data_50hz, data_10hz, target = train_set[:]\n",
    "\n",
    "print(data_50hz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici que la dimension est de 1 (=1 dataset) x 4 (=4 bandes) x nombre de signaux x 2 (=2 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
