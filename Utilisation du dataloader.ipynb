{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment utiliser le dataloader\n",
    "\n",
    "## Générer un train et test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.data import DreemDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres sont :\n",
    "\n",
    "- chemin vers les données\n",
    "- chemin vers les cibles\n",
    "- `keep_datasets` Liste des datasets à garder, parmi les suivants :\n",
    "    * `eeg_1` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_2` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_3` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_4` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_5` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_6` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_7` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `accelerometer_x` - Accelerometer along x axis sampled at 10 Hz -> 300 values\n",
    "    * `accelerometer_y` - Accelerometer along y axis sampled at 10 Hz -> 300 values\n",
    "    * `accelerometer_z` - Accelerometer along z axis sampled at 10 Hz -> 300 values\n",
    "    * `pulse_oximeter_infrared` - Pulse oximeter infrared channel sampled at 10 Hz -> 300 values\n",
    "- `split_train_val` Pourcentage pour partager le train set et validation set\n",
    "- `seed` Une seed pour la reproductibilité\n",
    "- `balance_data` si vrai, équilibre le dataset pour avoir le nombre de donnée par classe\n",
    "- `size` Une taille maximale pour le dataset (si non renseignée, tout le dataset)\n",
    "- `transforms` des transformations à appliquer aux données (voir la partie transformation)\n",
    "- `transforms_val` si renseignée, `transforms` sera pour le train et `transforms_val` pour la validation. Sinon, même transformation que `transforms`.\n",
    "\n",
    "\n",
    "### Avec context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', split_train_val=0.8, seed=0,\n",
    "                   size=5000, keep_datasets=['eeg_1']) as (train_set, val_set):\n",
    "    pass  # Faire des choses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "5412 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n",
      "Loading data in memory...\n",
      "1353 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=0, keep_datasets=['eeg_1']).get()\n",
    "\n",
    "train_set.load_data()  # Load les données en mémoire\n",
    "# train_set.load_data(npy_file)  # Load les données depuis un fichier de sauvegarde\n",
    "\n",
    "val_set.load_data()\n",
    "\n",
    "# Ne pas oublier de fermer les datasets\n",
    "\n",
    "train_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\n",
    "val_set.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "C'est un dictionnaire avec une fonction prenant un batch de signal en paramètre et renvoyant le batch transformé en valeur, et le nom du dataset en clé.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    \"eeg_1\": lambda signals: signals[:, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Des transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrait le spectre fenêtré\n",
    "from preprocessing.signals import ExtractSpectrum\n",
    "# Extrait les bandes de fréquences \n",
    "from preprocessing.signals import ExtractBands\n",
    "# Extrait des features\n",
    "from preprocessing.features import ExtractFeatures\n",
    "# Compose des fonctions entre elles\n",
    "from preprocessing import Compose\n",
    "\n",
    "extract_spectrum = ExtractSpectrum(window=10, sampling_freq=50)\n",
    "extract_bands = ExtractBands(bands='*')  # toutes les bandes\n",
    "# Extract features peut directement extraire les bandes\n",
    "extract_features = ExtractFeatures(bands='*', features=['mmd', 'esis'])\n",
    "\n",
    "transformations = {\n",
    "    \"eeg_1\": extract_spectrum,\n",
    "    \"eeg_2\": extract_bands,\n",
    "    \"eeg_3\": extract_features\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérer des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1500])\n"
     ]
    }
   ],
   "source": [
    "d50hz, d10hz, target = train_set[0]  # Une valeur\n",
    "# Dimension nb_datasets x tailles_features\n",
    "print(d50hz.shape)\n",
    "\n",
    "data50hz, data10hz, targets = train_set[0:10]  # 10 valeurs\n",
    "# Dimension nb_datasets x nb_elements x tailles_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrer un dataset\n",
    "\n",
    "On peut utiliser la méthode `save_data` pour enregistrer dans un `.npy`. Pour des questions de mémoire, il y aura un fichier par dataset (ex, si on choisit d'ouvrir `[\"eeg_1\", \"eeg_2\"]` alors il y aura deux fichiers).\n",
    "\n",
    "Attention, le nom des fichiers ne peut pas être précisé, seulement un dossier parent.\n",
    "\n",
    "Par exemple, avec le `save_data(\"dataset/test\")`, on aura les fichiers :\n",
    "- `dataset/test/eeg_1.npy`\n",
    "- `dataset/test/eeg_2.npy`\n",
    "\n",
    "On peut préciser le chemin vers un nouveau dossier, celui-ci sera créé.\n",
    "\n",
    "La sauvegarde enregistre les données **transformée**. Les données brutes ne sont pas enregistrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving into dataset/sauvegarde ...\n",
      "Loading dataset eeg_1 ...\n",
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=0, keep_datasets=['eeg_1']).get()\n",
    "\n",
    "train_set.save_data(\"dataset/sauvegarde/train\")  # Attention, pas de / à la fin !\n",
    "val_set.save_data(\"dataset/sauvegarde/val\")\n",
    "\n",
    "train_set.close()\n",
    "val_set.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on a déjà enregistré le dataset, on peut utiliser `load_data` en précisant le dossier dans lequel sont tous les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "5412 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n",
      "torch.Size([1, 1500])\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=0, keep_datasets=['eeg_1']).get()\n",
    "\n",
    "train_set.load_data(\"dataset/sauvegarde/train\")  # Attention, pas de / à la fin !\n",
    "val_set.load_data(\"dataset/sauvegarde/val\")\n",
    "\n",
    "train_set.close()\n",
    "val_set.close()\n",
    "\n",
    "print(train_set[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer le test\n",
    "\n",
    "On peut faire la même chose qu'avec les précédents...\n",
    "\n",
    "Attention à bien appeler `init()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "37439 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from tools.data import DreemDataset\n",
    "\n",
    "test_set = DreemDataset('dataset/test.h5', keep_datasets=['eeg_1']).init()\n",
    "\n",
    "test_set.load_data()\n",
    "\n",
    "test_set.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
