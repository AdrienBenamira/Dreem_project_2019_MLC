{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment utiliser le dataloader\n",
    "\n",
    "## Générer un train et test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.data import DreemDatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres sont :\n",
    "\n",
    "- chemin vers les données\n",
    "- chemin vers les cibles\n",
    "- `keep_datasets` Liste des datasets à garder, parmi les suivants :\n",
    "    * `eeg_1` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_2` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_3` - EEG in frontal position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_4` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_5` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_6` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `eeg_7` - EEG in frontal-occipital position sampled at 50 Hz -> 1500 values\n",
    "    * `accelerometer_x` - Accelerometer along x axis sampled at 10 Hz -> 300 values\n",
    "    * `accelerometer_y` - Accelerometer along y axis sampled at 10 Hz -> 300 values\n",
    "    * `accelerometer_z` - Accelerometer along z axis sampled at 10 Hz -> 300 values\n",
    "    * `pulse_oximeter_infrared` - Pulse oximeter infrared channel sampled at 10 Hz -> 300 values\n",
    "- `split_train_val` Pourcentage pour partager le train set et validation set\n",
    "- `seed` Une seed pour la reproductibilité\n",
    "- `balance_data` si vrai, équilibre le dataset pour avoir le nombre de donnée par classe\n",
    "- `size` Une taille maximale pour le dataset (si non renseignée, tout le dataset)\n",
    "- `transforms` des transformations à appliquer aux données (voir la partie transformation)\n",
    "- `transforms_val` si renseignée, `transforms` sera pour le train et `transforms_val` pour la validation. Sinon, même transformation que `transforms`.\n",
    "\n",
    "\n",
    "### Avec context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', split_train_val=0.8, seed=0,\n",
    "                   size=5000, keep_datasets=['eeg_1']) as (train_set, val_set):\n",
    "    pass  # Faire des choses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "Done.\n",
      "Loading data in memory...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=0, keep_datasets=['eeg_1']).get()\n",
    "\n",
    "train_set.load_data()  # Load les données en mémoire\n",
    "# train_set.load_data(npy_file)  # Load les données depuis un fichier de sauvegarde\n",
    "\n",
    "val_set.load_data()\n",
    "\n",
    "# Ne pas oublier de fermer les datasets\n",
    "\n",
    "train_set.close()  # Ne ferme que les fichiers h5. Si mis en mémoire, on a toujours accès aux données !\n",
    "val_set.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "C'est un dictionnaire avec une fonction prenant un batch de signal en paramètre et renvoyant le batch transformé en valeur, et le nom du dataset en clé.\n",
    "\n",
    "Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    \"eeg_1\": lambda signals: signals[:, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Des transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrait le spectre fenêtré\n",
    "from preprocessing.signals import ExtractSpectrum\n",
    "# Extrait les bandes de fréquences \n",
    "from preprocessing.signals import ExtractBands\n",
    "# Extrait des features\n",
    "from preprocessing.features import ExtractFeatures\n",
    "# Compose des fonctions entre elles\n",
    "from preprocessing import Compose\n",
    "\n",
    "extract_spectrum = ExtractSpectrum(window=10, sampling_freq=50)\n",
    "extract_bands = ExtractBands(bands='*')  # toutes les bandes\n",
    "# Extract features peut directement extraire les bandes\n",
    "extract_features = ExtractFeatures(bands='*', features=['mmd', 'esis'])\n",
    "\n",
    "transformations = {\n",
    "    \"eeg_1\": extract_spectrum,\n",
    "    \"eeg_2\": extract_bands,\n",
    "    \"eeg_3\": extract_features\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupérer des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d50hz, d10hz, target = train_set[0]  # Une valeur\n",
    "# Dimension nb_datasets x tailles_features\n",
    "\n",
    "data50hz, data10hz, targets = train_set[0:10]  # 10 valeurs\n",
    "# Dimension nb_datasets x nb_elements x tailles_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer le test\n",
    "\n",
    "A corriger..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function DreemDataset.__del__ at 0x7f8250c92400>\n",
      "Traceback (most recent call last):\n",
      "  File \"/run/media/bdvllrs/Data/Documents/Supelec/OMA/MLC/Projet/tools/data.py\", line 213, in __del__\n",
      "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
      "  File \"/run/media/bdvllrs/Data/Documents/Supelec/OMA/MLC/Projet/tools/data.py\", line 204, in close\n",
      "    def close(self):\n",
      "AttributeError: 'DreemDataset' object has no attribute 'data'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not a dataset (not a dataset)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1a3b86b44cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDreemDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset/test.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_datasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eeg_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/run/media/bdvllrs/Data/Documents/Supelec/OMA/MLC/Projet/tools/data.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading data in memory...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \"\"\"\n\u001b[1;32m    411\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEllipsis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty datasets cannot be sliced\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/h5py/_hl/base.py\u001b[0m in \u001b[0;36mis_empty_dataspace\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;34m\"\"\" Check if an object's dataspace is empty \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_simple_extent_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNULL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.get_space\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not a dataset (not a dataset)"
     ]
    }
   ],
   "source": [
    "from tools.data import DreemDataset\n",
    "\n",
    "test_set = DreemDataset('dataset/test.h5', keep_datasets=['eeg_1'])\n",
    "\n",
    "test_set.load_data()\n",
    "\n",
    "test_set.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
