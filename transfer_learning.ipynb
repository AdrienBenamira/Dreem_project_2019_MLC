{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from tools.data import DreemDatasets\n",
    "from preprocessing import WignerVilleSpectrum, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from mtspec.util import signal_bursts\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torchvision.models import vgg11\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_datasets = ['eeg_1']\n",
    "seed = 1\n",
    "batch_size = 4\n",
    "use_cuda = False\n",
    "lr = 0.1\n",
    "momentum = 0.5\n",
    "log_every = 10\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wigner_ville_spectrum = WignerVilleSpectrum(time_bandwidth=3.5)\n",
    "\n",
    "dataset_transform_spectrum = {\n",
    "    \"eeg_1\": wigner_ville_spectrum,\n",
    "    \"eeg_2\": wigner_ville_spectrum,\n",
    "    \"eeg_3\": wigner_ville_spectrum,\n",
    "    \"eeg_4\": wigner_ville_spectrum,\n",
    "    \"eeg_5\": wigner_ville_spectrum,\n",
    "    \"eeg_6\": wigner_ville_spectrum,\n",
    "    # \"eeg_7\": wigner_ville_spectrum\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données\n",
    "\n",
    "On est obligé de loader les données au fur et à mesure, sinon trop gros dataset (plus de 90Go !!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data in memory...\n",
      "5412 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n",
      "Loading data in memory...\n",
      "1353 in 1 datasets to load\n",
      "Loading dataset eeg_1 ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = DreemDatasets('dataset/train.h5', 'dataset/train_y.csv', \n",
    "                                   split_train_val=0.8, seed=seed, keep_datasets=use_datasets, \n",
    "                                   transforms=dataset_transform_spectrum, load_lazy=True).get()\n",
    "\n",
    "train_set.load_data(\"dataset/all_eegs/train\")\n",
    "val_set.load_data(\"dataset/all_eegs/val\")\n",
    "\n",
    "train_set.close()\n",
    "val_set.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 751, 1500)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "repeat() missing required argument 'repeats' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-77ecfd54cc2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: repeat() missing required argument 'repeats' (pos 1)"
     ]
    }
   ],
   "source": [
    "\"\"\"X, _, Y = train_set[6]\n",
    "print(X.shape)\n",
    "x = X.transpose(1, 2, 0)\n",
    "x -= x.min()\n",
    "x /= x.max()\n",
    "\n",
    "plt.imshow(x.repeat())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set.torch_dataset(), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_set.torch_dataset(), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_classes):\n",
    "    \"\"\"\n",
    "    Size of image at least 224x224\n",
    "    \"\"\"\n",
    "    model = vgg11(pretrained=True)\n",
    "    model_conv = nn.Sequential(*list(model.children())[:-1])\n",
    "    for param in model_conv.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.classifier = nn.Sequential(\n",
    "        #nn.Linear(512 * 7 * 7, 4096),\n",
    "        nn.Linear(141312, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, n_classes),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = get_model(n_classes=5)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data50):\n",
    "    data50 -= data50.min()\n",
    "    data50 /= data50.max()\n",
    "    data50 = data50.to(dtype=torch.float)\n",
    "    data50 = data50.expand(-1, 3, -1, -1)\n",
    "    data50 = nn.functional.interpolate(data50, (200, 1500))\n",
    "\n",
    "    return data50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(epoch):\n",
    "    model.train()\n",
    "    with tqdm(total=len(train_loader.dataset) / train_loader.batch_size) as t:\n",
    "        for batch_id, (data_50hz, data_10hz, target) in enumerate(train_loader):\n",
    "            if use_cuda:\n",
    "                data_50hz, data_10hz, target = data_50hz.cuda(), data_10hz.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            data50 = transform_data(data_50hz)\n",
    "            out50 = model(data50)\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss(reduction='elementwise_mean')\n",
    "            loss = criterion(out50, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_id % log_every == 0:\n",
    "                t.set_description(\"Train - Epoch \" + str(epoch))\n",
    "                t.set_postfix_str(\"Loss: \" + str(loss.data.item()))\n",
    "            t.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(epoch):\n",
    "    model.eval()\n",
    "\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    with tqdm(total=len(val_loader.dataset) / val_loader.batch_size) as t:\n",
    "        for batch_id, (data_50hz, data_10hz, target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                data_50hz, data_10hz, target = data_50hz.cuda(), data_10hz.cuda(), target.cuda()\n",
    "            \n",
    "            data50 = transform_data(data_50hz)\n",
    "            out50 = model(data50)\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss(reduction='elementwise_mean')\n",
    "            loss = criterion(out50, target)\n",
    "            \n",
    "            validation_loss += loss.data.item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = out50.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "            if batch_id % log_every == 0:\n",
    "                t.set_description(\"Val - Epoch \" + str(epoch))\n",
    "                t.set_postfix_str(\"Loss: \" + str(loss.data.item()))\n",
    "            t.update()\n",
    "\n",
    "        validation_loss /= len(val_loader.dataset) / batch_size\n",
    "        print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            validation_loss, correct, len(val_loader.dataset),\n",
    "            100. * correct / len(val_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1353.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 200, 1500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train - Epoch 0:   0%|          | 1/1353.0 [00:07<2:47:27,  7.43s/it, Loss: 1.5893125534057617]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 200, 1500])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    train_step(epoch)\n",
    "    val_step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
