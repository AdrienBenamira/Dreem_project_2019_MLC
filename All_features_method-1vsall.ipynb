{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all methods not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tools.csp import generate_projection, generate_eye, extract_feature\n",
    "from tools.filters import load_filterbank\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tools.data import DreemDatasets\n",
    "from preprocessing import Compose, ExtractBands, ExtractSpectrum\n",
    "from models.riemannian_multiscale import riemannian_multiscale\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParamÃ¨tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50.  # sampling frequency\n",
    "NO_channels = 7  # number of EEG channels\n",
    "NO_riem = int(NO_channels * NO_channels + 1) / 2  # Total number of CSP feature per band and timewindow\n",
    "bw = np.array([2, 4, 8, 13, 22])\n",
    "ftype = 'butter'  # 'fir', 'butter'\n",
    "forder = 2  # 4\n",
    "filter_bank = load_filterbank(bw, fs, order=forder, max_freq=23, ftype=ftype)  # get filterbank coeffs\n",
    "time_windows_flt = np.array([[0, 30],\n",
    "                             [15, 30],\n",
    "                             [10, 25],\n",
    "                             [5, 20],\n",
    "                             [0, 15],\n",
    "                             [15, 25],\n",
    "                             [10, 20],\n",
    "                             [5, 15],\n",
    "                             [0, 10]\n",
    "]) * fs\n",
    "\n",
    "#time_windows = time_windows[0:1]  # use only largest timewindow\n",
    "\n",
    "\n",
    "riem_opt = \"No_Adaptation\"  # {\"Riemann\",\"Riemann_Euclid\",\"Whitened_Euclid\",\"No_Adaptation\"}\n",
    "rho = 0.1\n",
    "\n",
    "time_windows = time_windows_flt.astype(int)\n",
    "NO_bands = filter_bank.shape[0]\n",
    "NO_csp = 24  # Total number of CSP feature per band and timewindow\n",
    "useCSP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, train=True):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/train_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "                X[0] = feature_0\n",
    "                del feature_0\n",
    "            else:\n",
    "                X[i] = np.load(\"dataset/\"+path+\"/test/eeg_\" + str(i + 1) + \".npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "    \n",
    "def get_data_extra_data_eeg(path, train=True):\n",
    "    if train:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/train_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/train_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/test/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/test/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "\n",
    "def get_extra_data(path, train=True):\n",
    "    if train:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/train_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        Y = np.load(\"dataset/\"+path+\"/train_split/targets.npy\")\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X, Y)\n",
    "    else:\n",
    "        use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "        for i in range(4):\n",
    "            if i==0:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                print(feature_0.shape)\n",
    "                X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "            else:\n",
    "                feature_0 = np.load(\"dataset/\"+path+\"/test/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "                X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "                del feature_0\n",
    "        X = X.transpose((1, 0, 2))\n",
    "        return(X)\n",
    "    \n",
    "def get_data_val(path):\n",
    "    for i in range(7):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "            X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]))\n",
    "            X[0] = feature_0\n",
    "            del feature_0\n",
    "        else:\n",
    "            X[i] = np.load(\"dataset/\"+path+\"/val_split/eeg_\" + str(i + 1) + \".npy\")\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "def get_extrat_data_val_eeg(path):\n",
    "    for i in range(7):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "            X = np.zeros((7, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "        else:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/eeg_\" + str(i + 1) + \".npy\").transpose((1, 0, 2))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "    Y = np.load(\"dataset/\"+path+\"/extra_eeg/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)\n",
    "\n",
    "def get_extra_data_val(path):\n",
    "    use_datasets = [\"accelerometer_x\",\"accelerometer_y\",\"accelerometer_z\",\"pulse_oximeter_infrared\"]\n",
    "    for i in range(4):\n",
    "        if i==0:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            print(feature_0.shape)\n",
    "            X = np.zeros((4, feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2]))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "        else:\n",
    "            feature_0 = np.load(\"dataset/\"+path+\"/val_split/\" + use_datasets[i] + \".npy\").transpose((1, 0, 2))\n",
    "            X[i] = feature_0.reshape(feature_0.shape[0], feature_0.shape[1]*feature_0.shape[2])\n",
    "            del feature_0\n",
    "    Y = np.load(\"dataset/\"+path+\"/val_split/targets.npy\")\n",
    "    X = X.transpose((1, 0, 2))\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4, 4)\n",
      "(7658, 4, 4)\n",
      "(7658, 7, 24)\n"
     ]
    }
   ],
   "source": [
    "path = \"all\"\n",
    "\n",
    "path = \"all\"\n",
    "train_extra_data, train_label = get_extra_data(path, train = True)\n",
    "path = \"all\"\n",
    "test_extra_data,test_label = get_extra_data_val(path)\n",
    "train_extra_data = train_extra_data.reshape(-1, 4*16)\n",
    "test_extra_data = test_extra_data.reshape(-1,  4*16)\n",
    "\n",
    "path = \"all\"\n",
    "train_extra_data_eeg, train_extra_label = get_data_extra_data_eeg(path, train = True)\n",
    "path = \"all\"\n",
    "test_extra_data_eeg,_ = get_extrat_data_val_eeg(path)\n",
    "print(test_extra_data_eeg.shape)\n",
    "train_extra_data_eeg = train_extra_data_eeg.reshape(-1, 7*24)\n",
    "test_extra_data_eeg = test_extra_data_eeg.reshape(-1,  7*24)\n",
    "\n",
    "\n",
    "\n",
    "features_CSP_train = np.load('dataset/features_CSP_false_allfenetres_sans0_train.npy')\n",
    "features_CSP_test = np.load('dataset/features_CSP_false_allfenetres_sans0_test.npy')\n",
    "features_CSP_train_R = np.load('dataset/features_R_allfenetres_sans0_train.npy')\n",
    "features_CSP_test_R = np.load('dataset/features_R_allfenetres_sans0_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min - max - freq - energy on pulse et accelerometre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[train_label!=2]=0\n",
    "train_label[train_label==2]=1\n",
    "\n",
    "test_label[test_label!=2]=0\n",
    "test_label[test_label==2]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3581  640]\n",
      " [1079 2358]] 0.7755288587098459 0.7696539245013516\n",
      "time :  81.70058083534241\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(train_extra_data, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(test_extra_data)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idem sur les eegs + mm et XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3548  673]\n",
      " [ 984 2453]] 0.7836249673544007 0.7791087373469516\n",
      "time :  143.83422875404358\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(train_extra_data_eeg, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(test_extra_data_eeg)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 232)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((train_extra_data_eeg, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((test_extra_data_eeg, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3670  551]\n",
      " [ 878 2559]] 0.8133977539827631 0.809385831125424\n",
      "time :  169.42565965652466\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec CSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juste CSP puis concatener avec les autres (csp-acc / csp-eeg / csp acc eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3468  753]\n",
      " [ 986 2451]] 0.7729172107599895 0.7688403755033246\n",
      "time :  413.5532314777374\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(features_CSP_train, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(features_CSP_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1198)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3528  693]\n",
      " [ 924 2513]] 0.7888482632541134 0.7850726009537248\n",
      "time :  407.9108784198761\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1302)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3496  725]\n",
      " [ 943 2494]] 0.7821885609819796 0.7783946693462427\n",
      "time :  426.95682740211487\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 1198)\n",
      "(30631, 1366)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3548  673]\n",
      " [ 863 2574]] 0.7994254374510316 0.7961274735733432\n",
      "time :  421.73396134376526\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rieman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idem avec Rieman au lieu de csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3549  672]\n",
      " [ 995 2442]] 0.7823191433794724 0.7776733920514654\n",
      "time :  899.695958852768\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(features_CSP_train_R, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(features_CSP_test_R)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4600)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3549  672]\n",
      " [ 970 2467]] 0.785583703316793 0.7812161413530653\n",
      "time :  997.3518524169922\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4704)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3565  656]\n",
      " [ 977 2460]] 0.7867589448942283 0.7822247268687019\n",
      "time :  1004.5266754627228\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4600)\n",
      "(30631, 4768)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3583  638]\n",
      " [ 942 2495]] 0.7936798119613476 0.7894294621659617\n",
      "time :  1130.5917494297028\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30631, 4600)\n",
      "(30631, 4768)\n",
      "(30631, 5902)\n"
     ]
    }
   ],
   "source": [
    "all_final_features = np.concatenate((features_CSP_train_R, train_extra_data), axis= 1)\n",
    "all_final_features_test = np.concatenate((features_CSP_test_R, test_extra_data), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, train_extra_data_eeg), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, test_extra_data_eeg), axis= 1)\n",
    "print(all_final_features.shape)\n",
    "\n",
    "all_final_features = np.concatenate((all_final_features, features_CSP_train), axis= 1)\n",
    "all_final_features_test = np.concatenate((all_final_features_test, features_CSP_test), axis= 1)\n",
    "print(all_final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "predicted\n",
      "[[3577  644]\n",
      " [ 932 2505]] 0.7942021415513189 0.79008880303911\n",
      "time :  992.3568811416626\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300,max_features='auto', random_state=0)\n",
    "clf.fit(all_final_features, train_label)\n",
    "print(\"trained\")\n",
    "\n",
    "labels_pred = clf.predict(all_final_features_test)\n",
    "print(\"predicted\")\n",
    "\n",
    "cm = confusion_matrix(test_label, labels_pred)\n",
    "acc = accuracy_score(test_label, labels_pred)\n",
    "f1 = f1_score(test_label, labels_pred, average='macro')\n",
    "print(cm, acc, f1)\n",
    "\n",
    "print(\"time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : \n",
    "\n",
    "Deal with unbalanced data et UP le label 1\n",
    "\n",
    "Normaliser les donnÃ©es (avant et aprÃ¨s le prÃ©proscess ?)\n",
    "\n",
    "Cross val et hyper parametres RF, SVM gradient boosting\n",
    "\n",
    "https://stats.stackexchange.com/questions/260736/multiclass-classification-having-class-imbalance-with-gradient-boosting-classifi\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "ya github \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}